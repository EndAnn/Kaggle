## Open Problems – Single-Cell Perturbations
##### Это решение (заняло 43е место из 1098, серебряная медаль) соревнования: https://www.kaggle.com/competitions/open-problems-single-cell-perturbations

## 1. Формализация [проекта](https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/overview)
<ins>Цель</ins>: моделировать, как малые молекулы лекарств изменяют дифференциальную экспрессию генов (differential expression (DE)), в различных типах клеток. Модель должна оценивать влияние экспериментального возмущения (chemical perturbations) лекарств на клетки, и, соответственно, уровень экспрессии каждого из 18211 генов в транскрипции. <br>

Модель поможет разработать методы предсказания того, как клетки реагируют на возмущения, вызванные малыми молекулами лекарств, что может иметь важное применение в открытии лекарств и фундаментальной биологии.

[<ins>Данные</ins>](https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/data): реальные экспериментальные данные, полученные по топовым технологиям (200 тысяч клеток секвенировали мультимодально).<br>

Тренировочная выборка: de_train.parquet (614 rows × 18216 columns), фичи “cell_type” (тип клеток крови, всего 6 типов), ”sm_name” (название лекарства), “sm_lincs_id ”) (ID соединения в стандартизированном представлении), “SMILES” (состав и структура молекулы лекарства), численные таргеты A1BG,…,A1BG-AS1 (дифференциальные экспрессии для каждого гена)<br>

Тестовая выборка: id_map.csv (255 rows × 2 columns) (фичи “cell_type”, ”sm_name”).<br>

Таким образом, для предсказания модели имеются две фичи, и они категориальные. В тренировочной и тестовой выборках сравнительно мало данных (614 и 255 объектов, соответственно). По своей сути задача состоит в генерализации на другие по сравнению с тренировочной выборкой “cell_type”

## 2.	Архитектура решения

<ins>Подход</ins>
Решение строилось на бленде двух моделей - PYBOOST и NN (удивительно, но нейронки хорошо работают даже при таком малом числе семплов): 0.5 Pyboost + 0.5 NN.

В распоряжении нашей команды имелось несколько моделей с очень высоким скором на публичном датасете, но эти модели представляли собой смесь большого количества моделей с разными коэффициентами. Такие модели могут дать плохой скор на закрытом частном датасете, будучи подогнанными под публичную таблицу лидеров. В результате команда выбрала две разработанные нами модели, которые не показали очень высоких результатов на публичном датасете, но являлись более стабильными. 

Почему выбран PYBOOST: датасет имеет особенности, во-первых, для предсказания модели имеются только две фичи, но таргетов много − 18211 (все гены). Для такого типа задач идеально подходит модель PYBOOST.



