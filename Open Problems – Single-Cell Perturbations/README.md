## Open Problems – Single-Cell Perturbations
##### Это решение (43е место из 1098, серебряная медаль) соревнования: https://www.kaggle.com/competitions/open-problems-single-cell-perturbations

## 1. Формализация [проекта](https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/overview)
<ins>Цель</ins>: моделировать, как малые молекулы лекарств изменяют дифференциальную **экспрессию генов** (differential expression (DE)), в различных типах клеток. Модель должна оценивать влияние экспериментального **возмущения** (chemical perturbations) лекарств на клетки, и, соответственно, уровень экспрессии каждого из 18211 генов в транскрипции. <br>

Модель поможет разработать методы предсказания того, как клетки реагируют на **возмущения**, вызванные малыми молекулами лекарств, что может иметь важное применение в открытии лекарств и фундаментальной биологии.

[<ins>Данные</ins>](https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/data): реальные экспериментальные данные, полученные по топовым технологиям (200 тысяч клеток секвенировали мультимодально).<br>

Тренировочная выборка: de_train.parquet (614 rows × 18216 columns), фичи “cell_type” (тип клеток крови, всего 6 типов), ”sm_name” (название лекарства), “sm_lincs_id ”) (ID соединения в стандартизированном представлении), “SMILES” (состав и структура молекулы лекарства), численные таргеты A1BG,…,A1BG-AS1 (дифференциальные экспрессии для каждого гена)<br>

Тестовая выборка: id_map.csv (255 rows × 2 columns) (фичи “cell_type”, ”sm_name”).<br>

Таким образом, для предсказания модели имеются две фичи, и они категориальные. В тренировочной и тестовой выборках сравнительно мало данных (614 и 255 объектов, соответственно). По своей сути задача состоит в генерализации на другие по сравнению с тренировочной выборкой “cell_type”

## 2.	Архитектура решения

<ins>Подход</ins>
Решение строилось на бленде двух моделей - PYBOOST и NN (удивительно, но нейронки хорошо работают даже при таком малом числе семплов): 0.5 Pyboost + 0.5 NN.

В распоряжении нашей команды имелось несколько моделей с очень высоким скором на публичном датасете, но эти модели представляли собой смесь большого количества моделей с разными коэффициентами. Такие модели могут дать плохой скор на закрытом частном датасете, будучи подогнанными под публичную таблицу лидеров. В результате команда выбрала две разработанные нами модели, которые не показали очень высоких результатов на публичном датасете, но являлись более стабильными. 

Почему выбран PYBOOST: датасет имеет особенности, во-первых, для предсказания модели имеются только две фичи, но таргетов много − 18211 (все гены). Для такого типа задач идеально подходит модель PYBOOST.

<ins>Признаки</ins>

1) **Pyboost**: Наше главное улучшение по сравнению с [публичной реализацией pyboost](https://www.kaggle.com/code/alexandervc/pyboost-s+ecret-grandmaster-s-tool) заключалось в том, что мы исследовали и добавили категории для каждого препарата в качестве признака (drug_cls). Например, категория «Antibiotic» для препаратов [«Isoniazid»,«Doxorubicin»] из «sm_name».

Другими признаками были «cell_type» и «sm_name», закодированные с помощью QuantileEncoder.

2) **NN**: Модель NN построена на основе фичей “cell_type” и “SMILES”. Текстовые данные из “SMILES” преобразуются в эмбеддинги, после чего преобразованные данные и данные из «sm_name» конкатенируются.

<ins>Модель</ins>

1) **Pyboost**: параметры модели n_components = 50, max_depth = 10, ntrees = 5000, 
subsample = 1, colsample = 0.35, lr = 0.01
2) **NN** Конкатенированные преобразованные данные обрабатываются в полносвязных слоях. Затем следует обработка в отдельных ветвях для объединения всех извлечённых и обогащённых признаков, после чего происходит конкатенация выходных данных ветвей для получения выходных данных.

## 3.	Результат

Оцениваемая метрика - MRRMSE(Mean Rowwise Root Mean Sqared Error), чтобы оценивать ошибку модели на уровне отдельных строк.

Был получен результат MRRMSE= 0.756 (43 место) в сопоставлении с наилучшим результатом MRRMSE= 0.729 

## Личный объем участия

1.	Работа над подбором параметров Pyboost
   
3.	Участие в разработке NN
   
5.	Блендинг итоговых моделей

## Ссылки
[https://www.kaggle.com/code/alexandervc/pyboost-secret-grandmaster-s-tool](https://www.kaggle.com/code/alexandervc/pyboost-secret-grandmaster-s-tool)

[https://www.kaggle.com/code/asimandia/kfold-simple-nn-refactored](https://www.kaggle.com/code/asimandia/kfold-simple-nn-refactored)
